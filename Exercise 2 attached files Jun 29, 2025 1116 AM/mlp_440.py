# -*- coding: utf-8 -*-
"""MLP_440.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f_JSVKVLVL6XdD0vqnkrHJh4Y4k-K9tp
"""

from sklearn.datasets import fetch_openml
#load mice protein dataset from OpenML
mice = fetch_openml(name='miceprotein', version=4, as_frame=True)
list(mice.frame.columns)
#print(mice.details)
#mice.frame.describe()


# Import required libraries
import numpy as np 
import sklearn
from sklearn.neural_network import MLPClassifier


# Import model to divide data into training and testing sets
from sklearn.model_selection import train_test_split


target_column = ['class'] 
#derive the list of predictor column id's
predictors = list(set(list(mice.frame.columns))-set(target_column))
#standardize the predictors by diividing by the maximum
mice.frame[predictors] = mice.frame[predictors]/mice.frame[predictors].max()
#provide summary statistics for the dataframe
mice.frame.describe().transpose()

#Get rid of any rown with NA's
mice.frame = mice.frame.dropna()

#the input data
X = mice.frame[predictors].values
#the output data
y = mice.frame[target_column].values

#we encode target classes from strings to numbers as neural networks cannot require all numerical inputs and outputs
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

#divide data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)
print(X_train.shape); print(X_test.shape)

#impor the neural network (aka multi-layer-perceptron library)
from sklearn.neural_network import MLPClassifier

#The network architecture will consist of 1 input layer that has as many input nodes as columns-1, 3 hidden layers of 20 nodes each,
# and an output layer with a node for each of the categories--and the network will choose the one with the highest score
mlp = MLPClassifier(hidden_layer_sizes=(15,15,15), activation='relu', solver='adam', max_iter=2000)
#mlp = MLPClassifier(hidden_layer_sizes=(20,20,20), activation='relu', solver='adam', max_iter=5000)
#we train the network
mlp.fit(X_train,y_train)

#We predict the training set
predict_train = mlp.predict(X_train)
#we predict the test set
predict_test = mlp.predict(X_test)

from sklearn.metrics import classification_report,confusion_matrix

print('Training accuracy')
#we report the confusion matrix for the training set
print(confusion_matrix(y_train,predict_train))
#we report various accuracy statistics for the training set
print(classification_report(y_train,predict_train))

print('Testing accuracy')
#we report the confusion matrix for the test set
print(confusion_matrix(y_test,predict_test))
#we report various accuracy statistics for the test set
print(classification_report(y_test,predict_test))

#Now rerun but above change the network architecture to 
#mlp = MLPClassifier(hidden_layer_sizes=(20,20,20), activation='relu', solver='adam', max_iter=5000)